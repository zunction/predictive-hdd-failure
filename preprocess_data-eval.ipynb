{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process all the raw downloaded CSV to remove cols we don't want, and fill in null/NaN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Files:\n",
      "From: ./data_Q418/2018-12-31.csv , to: ./data_Q418/2018-10-01.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import glob\n",
    "\n",
    "data_files = glob.glob(\"./data_Q418/*.csv\")\n",
    "#data_files = glob.glob(\"./data/*.csv\")\n",
    "data_files.sort()\n",
    "data_files = data_files[::-1]\n",
    "print(len(data_files), \"Files:\")\n",
    "print(\"From:\", data_files[0], \", to:\", data_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_files = data_files[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols_ = [\"smart_177\", \"smart_179\", \"smart_181\", \"smart_182\", \"smart_235\"]\n",
    "remove_cols_ += [\"smart_23\", \"smart_24\"]\n",
    "remove_cols_ += [\"smart_16\", \"smart_17\", \"smart_168\", \"smart_170\", \"smart_173\", \"smart_174\", \"smart_218\", \"smart_231\", \"smart_232\", \"smart_233\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = [col+\"_raw\" for col in remove_cols_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    cols = df.columns.values.tolist() \n",
    "    for col in cols:\n",
    "        if \"norm\" in col:\n",
    "            df = df.drop(col, axis=1)\n",
    "        elif (col in remove_cols):\n",
    "            df = df.drop(col, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5281445f7d1e4b28920bd7e262a1c249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./data_Q418/2018-12-31.csv\n",
      "File: ./data_Q418/2018-12-30.csv\n",
      "File: ./data_Q418/2018-12-29.csv\n",
      "File: ./data_Q418/2018-12-28.csv\n",
      "File: ./data_Q418/2018-12-27.csv\n",
      "File: ./data_Q418/2018-12-26.csv\n",
      "File: ./data_Q418/2018-12-25.csv\n",
      "File: ./data_Q418/2018-12-24.csv\n",
      "File: ./data_Q418/2018-12-23.csv\n",
      "File: ./data_Q418/2018-12-22.csv\n",
      "File: ./data_Q418/2018-12-21.csv\n",
      "File: ./data_Q418/2018-12-20.csv\n",
      "File: ./data_Q418/2018-12-19.csv\n",
      "File: ./data_Q418/2018-12-18.csv\n",
      "File: ./data_Q418/2018-12-17.csv\n",
      "File: ./data_Q418/2018-12-16.csv\n",
      "File: ./data_Q418/2018-12-15.csv\n",
      "File: ./data_Q418/2018-12-14.csv\n",
      "File: ./data_Q418/2018-12-13.csv\n",
      "File: ./data_Q418/2018-12-12.csv\n",
      "File: ./data_Q418/2018-12-11.csv\n",
      "File: ./data_Q418/2018-12-10.csv\n",
      "File: ./data_Q418/2018-12-09.csv\n",
      "File: ./data_Q418/2018-12-08.csv\n",
      "File: ./data_Q418/2018-12-07.csv\n",
      "File: ./data_Q418/2018-12-06.csv\n",
      "File: ./data_Q418/2018-12-05.csv\n",
      "File: ./data_Q418/2018-12-04.csv\n",
      "File: ./data_Q418/2018-12-03.csv\n",
      "File: ./data_Q418/2018-12-02.csv\n",
      "File: ./data_Q418/2018-12-01.csv\n",
      "File: ./data_Q418/2018-11-30.csv\n",
      "File: ./data_Q418/2018-11-29.csv\n",
      "File: ./data_Q418/2018-11-28.csv\n",
      "File: ./data_Q418/2018-11-27.csv\n",
      "File: ./data_Q418/2018-11-26.csv\n",
      "File: ./data_Q418/2018-11-25.csv\n",
      "File: ./data_Q418/2018-11-24.csv\n",
      "File: ./data_Q418/2018-11-23.csv\n",
      "File: ./data_Q418/2018-11-22.csv\n",
      "File: ./data_Q418/2018-11-21.csv\n",
      "File: ./data_Q418/2018-11-20.csv\n",
      "File: ./data_Q418/2018-11-19.csv\n",
      "File: ./data_Q418/2018-11-18.csv\n",
      "File: ./data_Q418/2018-11-17.csv\n",
      "File: ./data_Q418/2018-11-16.csv\n",
      "File: ./data_Q418/2018-11-15.csv\n",
      "File: ./data_Q418/2018-11-14.csv\n",
      "File: ./data_Q418/2018-11-13.csv\n",
      "File: ./data_Q418/2018-11-12.csv\n",
      "File: ./data_Q418/2018-11-11.csv\n",
      "File: ./data_Q418/2018-11-10.csv\n",
      "File: ./data_Q418/2018-11-09.csv\n",
      "File: ./data_Q418/2018-11-08.csv\n",
      "File: ./data_Q418/2018-11-07.csv\n",
      "File: ./data_Q418/2018-11-06.csv\n",
      "File: ./data_Q418/2018-11-05.csv\n",
      "File: ./data_Q418/2018-11-04.csv\n",
      "File: ./data_Q418/2018-11-03.csv\n",
      "File: ./data_Q418/2018-11-02.csv\n",
      "File: ./data_Q418/2018-11-01.csv\n",
      "File: ./data_Q418/2018-10-31.csv\n",
      "File: ./data_Q418/2018-10-30.csv\n",
      "File: ./data_Q418/2018-10-29.csv\n",
      "File: ./data_Q418/2018-10-28.csv\n",
      "File: ./data_Q418/2018-10-27.csv\n",
      "File: ./data_Q418/2018-10-26.csv\n",
      "File: ./data_Q418/2018-10-25.csv\n",
      "File: ./data_Q418/2018-10-24.csv\n",
      "File: ./data_Q418/2018-10-23.csv\n",
      "File: ./data_Q418/2018-10-22.csv\n",
      "File: ./data_Q418/2018-10-21.csv\n",
      "File: ./data_Q418/2018-10-20.csv\n",
      "File: ./data_Q418/2018-10-19.csv\n",
      "File: ./data_Q418/2018-10-18.csv\n",
      "File: ./data_Q418/2018-10-17.csv\n",
      "File: ./data_Q418/2018-10-16.csv\n",
      "File: ./data_Q418/2018-10-15.csv\n",
      "File: ./data_Q418/2018-10-14.csv\n",
      "File: ./data_Q418/2018-10-13.csv\n",
      "File: ./data_Q418/2018-10-12.csv\n",
      "File: ./data_Q418/2018-10-11.csv\n",
      "File: ./data_Q418/2018-10-10.csv\n",
      "File: ./data_Q418/2018-10-09.csv\n",
      "File: ./data_Q418/2018-10-08.csv\n",
      "File: ./data_Q418/2018-10-07.csv\n",
      "File: ./data_Q418/2018-10-06.csv\n",
      "File: ./data_Q418/2018-10-05.csv\n",
      "File: ./data_Q418/2018-10-04.csv\n",
      "File: ./data_Q418/2018-10-03.csv\n",
      "File: ./data_Q418/2018-10-02.csv\n",
      "File: ./data_Q418/2018-10-01.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT_DIR = \"./processed/\"\n",
    "OUTPUT_DIR = \"./eval/\"\n",
    "\n",
    "for n,data_file in tqdm_notebook(enumerate(data_files), total=len(data_files)):\n",
    "    print(\"File:\", data_file)\n",
    "    df = pd.read_csv(data_file)\n",
    "    df = preprocess_df(df)\n",
    "    #df.to_csv(OUTPUT_DIR+data_file.replace(\"./data/\",\"\"))\n",
    "    df.to_csv(OUTPUT_DIR+data_file.replace(\"./data_Q418/\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
